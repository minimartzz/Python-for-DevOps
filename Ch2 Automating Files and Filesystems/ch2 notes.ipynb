{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Automating Files and Filesystems\n",
    "\n",
    "In DevOps, you are continually parsing, searching and changing the text in files. Files are a means of persisting the state of data, code and configuration.\n",
    "\n",
    "Rather than keeping a set of instructions to follow manually, automating the process of updating configurations helps to reduce errors and saves time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Files\n",
    "\n",
    "__Opening files__\n",
    "* `open` function to create a file object that can read and write files\n",
    "\t- `path`: path of the file\n",
    "\t- `mode`: mode to edit the file; specify the type of file (text, binary, etc)\n",
    "* `read` method returns contents of file as a string\n",
    "\n",
    "__Readlines__\n",
    "* `readlines` method splits content on newline characters, returns a list of strings, each is one line\n",
    "\n",
    "__with statements__\n",
    "* Do not need to close a file explicitly, Python will close when out of the idented block\n",
    "\n",
    "__Opening Binary files__\n",
    "* Windows systems use `\\r\\n` for newline, Unix systems use `\\n`\n",
    "* Binary files like _.jpeg_ images, are likely to be corrupted if opened as text\n",
    "* Appending a `b` to mode, will prevent this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2965\n",
      "n\n",
      "Length of text: 72\n",
      "Will they know what you overcame?\n",
      "\n",
      "In New York you can be a new man (just you wait)\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Read File\n",
    "file_path = \"hamilton.txt\"\n",
    "open_file = open(file_path, \"r\")\n",
    "text = open_file.read()\n",
    "print(f\"Length of text: {len(text)}\")\n",
    "print(text[56])\n",
    "open_file.close()\n",
    "\n",
    "# Readlines\n",
    "file_path = \"hamilton.txt\"\n",
    "open_file = open(file_path, \"r\")\n",
    "text = open_file.readlines()\n",
    "print(f\"Length of text: {len(text)}\")\n",
    "print(text[56])\n",
    "open_file.close()\n",
    "\n",
    "# with statement\n",
    "with open(file_path, \"r\") as open_file:\n",
    "\ttext = open_file.readlines()\n",
    "print(text[42])\n",
    "\n",
    "# Opening a binary file\n",
    "file_path = \"1584529319.jpg\"\n",
    "with open(file_path, \"rb\") as open_file:\n",
    "\tbtext = open_file.read()\n",
    "print(btext[28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write to file__\n",
    "* `w` argument: used to write to a file\n",
    "* _For DevOps_: tool `direnv` used to automatically setup development environments. It will scan through the directory and find files with extensions `.envrc` to create the environment.\n",
    "\t- Writes are good to edit this file to specify the type of environment\n",
    "* Will overwrite files if already exists\n",
    "\n",
    "__Append to existing file__\n",
    "* `a` argum,ent: appends new text to the end of the file\n",
    "\n",
    "Similarly, binary files have the additional `b` argument at the back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''export STAGE=PROD\n",
    "export TABLE_ID=token-storage-1234'''\n",
    "\n",
    "with open(\".envrc\", \"w\") as opened_file:\n",
    "\topened_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good practice to close a file when finished with it. Python closes a file when it is out of scope, but until then the file will continue to consume resoures and may prevent other processes from opening it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to `pathlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "path = pathlib.Path(\"hamilton.txt\")\n",
    "path.read_text()\n",
    "\n",
    "path = pathlib.Path(\".envrc\")\n",
    "path.write_text(\"LOG:DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with JSON\n",
    "\n",
    "Use the `json` module\n",
    "\n",
    "__Opening a JSON file__\n",
    "* `json.load()`: Using the open syntax to open the file, then convert it to a dictionary\n",
    "\n",
    "__Writing a JSON file__\n",
    "* `json.dump()`: Using the open syntax to open the file, then write a dictionary to the JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Statement': {'Action': 'service-prefix:action-name',\n",
      "               'Condition': {'DateGreaterThan': {'aws:CurrentTime': '2017-07-01T00:00:00Z'},\n",
      "                             'DateLessThan': {'aws:CurrentTime': '2017-12-31T23:59:59Z'}},\n",
      "               'Effect': 'Allow',\n",
      "               'Resource': '*'},\n",
      " 'Version': '2012-10-17'}\n",
      "{'Statement': {'Action': 'service-prefix:action-name',\n",
      "               'Condition': {'DateGreaterThan': {'aws:CurrentTime': '2017-07-01T00:00:00Z'},\n",
      "                             'DateLessThan': {'aws:CurrentTime': '2017-12-31T23:59:59Z'}},\n",
      "               'Effect': 'Allow',\n",
      "               'Resource': 'S3'},\n",
      " 'Version': '2012-10-17'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "with open('deploy.json', 'r') as opened_file:\n",
    "\tpolicy = json.load(opened_file)\n",
    "pprint(policy)\n",
    "\n",
    "# Changing the resource access to \"S3\"\n",
    "policy[\"Statement\"][\"Resource\"] = \"S3\"\n",
    "pprint(policy)\n",
    "\n",
    "# Writing to JSON\n",
    "new_dict = {\n",
    "\t\"Statement\": {\n",
    "\t\t\"Action\": \"service-prefix:action-name\",\n",
    "\t\t\"Condition\": {\n",
    "\t\t\t\"Something\": \"Greater than 10\"\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"Version\": \"2020-10-18\"\n",
    "}\n",
    "with open(\"new_deploy.json\", \"w\") as opened_file:\n",
    "\tjson.dump(new_dict, opened_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with YAML\n",
    "\n",
    "Yet Another Markup Language. Superset of JSON with a more compact format using whitespaces.\n",
    "\n",
    "Ansible uses YAML format for their _playbooks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hosts': 'webservers',\n",
      "  'tasks': [{'name': 'ensure apache is at the latest version',\n",
      "             'yum': {'name': 'httpd', 'state': 'latest'}}],\n",
      "  'vars': {'http_port': 80, 'max_clients': 200, 'remote_user': 'root'}}]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"playbook.yaml\", \"r\") as opened_file:\n",
    "\tverify_apache = yaml.safe_load(opened_file)\n",
    "pprint(verify_apache)\n",
    "\n",
    "with open(\"new_playbook.yaml\", \"w\") as written_file:\n",
    "\tyaml.dump(new_dict, written_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with XML\n",
    "\n",
    "Stands for Extensible Markup Language\n",
    "* Consists of hierarchical documents of tagged elements\n",
    "* Web systems used XML to transport data e.g Real Simple Syndication (RSS) feeds\n",
    "\t- RSS feeds used XML-formated pages to track and notify users of updates to websites \n",
    "* Python maps XML documents' hierarchical structure to a tree-like data structure. Nodes are elements and a parent-child relationship is used to model the hierarchy\n",
    "\n",
    "Use the `xml` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'catalog' at 0x0000020A6929AD90>\n",
      "book {'id': 'bk101'}\n",
      "book {'id': 'bk102'}\n",
      "book {'id': 'bk103'}\n",
      "book {'id': 'bk104'}\n",
      "book {'id': 'bk105'}\n",
      "book {'id': 'bk106'}\n",
      "book {'id': 'bk107'}\n",
      "book {'id': 'bk108'}\n",
      "book {'id': 'bk109'}\n",
      "book {'id': 'bk110'}\n",
      "book {'id': 'bk111'}\n",
      "book {'id': 'bk112'}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(\"books.xml\")\n",
    "root = tree.getroot()\n",
    "print(root)\n",
    "\n",
    "# iterating over child nodes\n",
    "for child in root:\n",
    "\tprint(child.tag, child.attrib)\n",
    "\n",
    "# namespacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with CSV\n",
    "\n",
    "Use either the `csv` or `pandas` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataMessageGUID', 'SensorID', 'Sensor Name', 'Date', 'Value', 'Formatted Value', 'Battery', 'Raw Data', 'Sensor State', 'GatewayID', 'Alert Sent', 'Signal Strength', 'Voltage', 'Special Export Value']\n",
      "['b67432ae-2bbb-42b2-8414-bec45135ca66', '630899', 'G-force - Max & Avg - 630899', '05/17/2022 12:02 AM', '0.059', 'X Max: 0.059 g , Y Max: 0.866 g , Z Max: 0.463 g , Magnitude Max: 0.975 g , X Avg: 0.05 g , Y Avg: 0.855 g , Z Avg: 0.442 g , Magnitude Mean: 0.964 g', '100', '0.059|0.866|0.463|0.975|0.05|0.855|0.442|0.964|0', '0', '971850', 'False', '0', '2.99']\n",
      "['5d060b22-36d2-4c7f-9ec4-b4f8cf85d5cd', '630899', 'G-force - Max & Avg - 630899', '05/17/2022 12:12 AM', '0.16', 'X Max: 0.16 g , Y Max: 0.946 g , Z Max: 0.554 g , Magnitude Max: 1.044 g , X Avg: 0.03 g , Y Avg: 0.843 g , Z Avg: 0.462 g , Magnitude Mean: 0.961 g', '100', '0.16|0.946|0.554|1.044|0.03|0.843|0.462|0.961|0', '0', '971850', 'False', '0', '2.99']\n",
      "['03ad74ec-6535-422f-a30a-c89a9db45831', '630899', 'G-force - Max & Avg - 630899', '05/17/2022 12:22 AM', '0.04', 'X Max: 0.04 g , Y Max: 0.85 g , Z Max: 0.475 g , Magnitude Max: 0.97 g , X Avg: 0.031 g , Y Avg: 0.842 g , Z Avg: 0.464 g , Magnitude Mean: 0.961 g', '100', '0.04|0.85|0.475|0.97|0.031|0.842|0.464|0.961|0', '0', '971850', 'False', '0', '2.99']\n",
      "['423ccdd5-431a-4864-8831-288babf3cb00', '630899', 'G-force - Max & Avg - 630899', '05/17/2022 12:32 AM', '0.039', 'X Max: 0.039 g , Y Max: 0.85 g , Z Max: 0.477 g , Magnitude Max: 0.972 g , X Avg: 0.031 g , Y Avg: 0.842 g , Z Avg: 0.465 g , Magnitude Mean: 0.961 g', '100', '0.039|0.85|0.477|0.972|0.031|0.842|0.465|0.961|0', '0', '971850', 'False', '0', '2.96']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"NewReport.csv\"\n",
    "with open(file_path, newline=\"\") as csv_file:\n",
    "\toff_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "\tfor _ in range(5):\n",
    "\t\tprint(next(off_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      630899\n",
       "1      630899\n",
       "2      630899\n",
       "3      630899\n",
       "4      630899\n",
       "        ...  \n",
       "210    630899\n",
       "211    630899\n",
       "212    630899\n",
       "213    630899\n",
       "214    630899\n",
       "Name: SensorID, Length: 215, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NewReport.csv\")\n",
    "df.head()\n",
    "df.describe()\n",
    "df[\"SensorID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using regex to Search Text\n",
    "\n",
    "* Apache HTTP server is an open source web server widely used to serve web content\n",
    "* Server can be configured to save log files in different formats\n",
    "\t- Common Log Format (CLF) below\n",
    "\n",
    "```\n",
    "<IP Address> <Client Id> <User Id> <Time> <Request> <Status> <Size>\n",
    "127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] \"GET /assets/234 HTTP/1.0\" \n",
    "200 2326\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Pulling out IP address from a line\n",
    "line = '127.0.0.1 - rj [13/Nov/2019:14:43:30] \"GET HTTP/1.0\" 200'\n",
    "re.search(r\"(?P<IP>\\d+\\.\\d+\\.\\d+\\.\\d+)\", line)\n",
    "\n",
    "m = re.search(r\"(?P<IP>\\d+\\.\\d+\\.\\d+\\.\\d+)\", line)\n",
    "print(m.group(\"IP\"))\n",
    "\n",
    "# Getting time\n",
    "r = r\"\\[(?P<Time>\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2})\\]\"\n",
    "m = re.search(r, line)\n",
    "print(m.group(\"Time\"))\n",
    "\n",
    "# Multiple Elements\n",
    "r = r\"(?P<IP>\\d+\\.\\d+\\.\\d+\\.\\d+)\"\n",
    "r += r\" - (?P<User>\\w+) \"\n",
    "r += r\"\\[(?P<Time>\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2})\\]\"\n",
    "r += r' (?P<Request>\".+\")'\n",
    "m = re.search(r, line)\n",
    "print(m.group(\"User\"))\n",
    "print(m.group(\"Request\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regex to pull information from the whole log. E.g pulling all of the IP addresses for the GET request that happened on November 9, 2019. Able to make modifications based on teh specifics of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r\"(?P<IP>\\d+\\.\\d+\\.\\d+\\.\\d+)\"\n",
    "r += r\" - (?P<User>\\w+) \"\n",
    "r += r\"\\[(?P<Time>08/Nov/2019:\\d{2}:\\d{2}:\\d{2})\\]\"\n",
    "r += r' (?P<Request>\"GET .+\")'\n",
    "\n",
    "# access_log is a fake log file\n",
    "matched = re.search(r, access_log)\n",
    "for m in matched:\n",
    "    print(m.group(\"IP\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Large Files\n",
    "\n",
    "Instead of loading the entire file into memory, read one line at a time. Python will process the line and automatically remove read lines from memory.\n",
    "\n",
    "Different operating systems use alternate line endings (e.g Windows: `\\r\\n` Mac and Linux: `\\n`), so it's difficult to account for different line breaks for the different OS-es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using linebreaks as a separator\n",
    "with open(\"big-data.txt\", 'r') as source_file:\n",
    "    with open(\"big-data-corrected.txt\", \"w\") as target_file:\n",
    "        for line in source_file:\n",
    "            target_file.write(line)\n",
    "\n",
    "# generator function for multiple files\n",
    "def line_reader(file_path):\n",
    "    with open(file_path, \"r\") as source_file:\n",
    "        for line in source_file:\n",
    "            yield line\n",
    "\n",
    "reader = line_reader(\"big-data.txt\")\n",
    "with open(\"big-data-corrected.txt\", \"w\") as target_file:\n",
    "    for line in reader:\n",
    "        target_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large binary files, can read the data in chunks. Pass the number of bytes read in each chunk to the file objects `read` method. Will retrun an empty string when its at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2115878dd1ef391a02cbe6f36d5381fa4da0f9ab2909cc6bc4d8b996bb555e97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
